{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense,Embedding,GRU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import RNN, LSTM, RepeatVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open file and prepare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 unique characters\n",
      "char2idx:\n",
      " {'\\n': 0, ' ': 1, '!': 2, '(': 3, ')': 4, ',': 5, '-': 6, '.': 7, ':': 8, ';': 9, '?': 10, 'A': 11, 'B': 12, 'C': 13, 'D': 14, 'E': 15, 'F': 16, 'G': 17, 'H': 18, 'I': 19, 'J': 20, 'K': 21, 'L': 22, 'M': 23, 'N': 24, 'O': 25, 'P': 26, 'R': 27, 'S': 28, 'T': 29, 'U': 30, 'V': 31, 'W': 32, 'Z': 33, 'a': 34, 'b': 35, 'c': 36, 'd': 37, 'e': 38, 'f': 39, 'g': 40, 'h': 41, 'i': 42, 'j': 43, 'k': 44, 'l': 45, 'm': 46, 'n': 47, 'o': 48, 'p': 49, 'q': 50, 'r': 51, 's': 52, 't': 53, 'u': 54, 'v': 55, 'w': 56, 'x': 57, 'y': 58, 'z': 59, 'Ó': 60, 'à': 61, 'é': 62, 'ó': 63, 'ą': 64, 'Ć': 65, 'ć': 66, 'ę': 67, 'Ł': 68, 'ł': 69, 'ń': 70, 'Ś': 71, 'ś': 72, 'Ź': 73, 'ź': 74, 'Ż': 75, 'ż': 76, '—': 77, '’': 78, '“': 79, '„': 80}\n",
      "idx2char\n",
      " ['\\n' ' ' '!' '(' ')' ',' '-' '.' ':' ';' '?' 'A' 'B' 'C' 'D' 'E' 'F' 'G'\n",
      " 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'R' 'S' 'T' 'U' 'V' 'W' 'Z' 'a' 'b'\n",
      " 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's' 't'\n",
      " 'u' 'v' 'w' 'x' 'y' 'z' 'Ó' 'à' 'é' 'ó' 'ą' 'Ć' 'ć' 'ę' 'Ł' 'ł' 'ń' 'Ś'\n",
      " 'ś' 'Ź' 'ź' 'Ż' 'ż' '—' '’' '“' '„']\n"
     ]
    }
   ],
   "source": [
    "fin = open('pan_tadeusz.txt', 'rb')\n",
    "dataset_txt = fin.read().decode(encoding='utf-8')\n",
    "fin.close()\n",
    "\n",
    "# Obtain the unique characters\n",
    "vocab = sorted(set(dataset_txt))\n",
    "print ('{} unique characters'.format(len(vocab)))\n",
    "\n",
    "# Create a mapping from unique characters to indices\n",
    "char2idx = {char:index for index, char in enumerate(vocab)}\n",
    "print('char2idx:\\n',char2idx)\n",
    "idx2char = np.array(vocab)\n",
    "print('idx2char\\n',idx2char)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Convert the dataset from 'characters' to 'integers'\n",
    "dataset_int = np.array([char2idx[char] for char in dataset_txt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_text(sample):\n",
    "    return ''.join([idx2char[int(x)] for x in sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare samples and labels\n",
    "- Every label is the text shifted by one letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples[0]:\n",
      "Litwo, Ojczyzno moja! ty jesteś jak zdrowie; \n",
      "Ile cię trzeba cenić, ten tylko się dowie, \n",
      "Kto cię st\n",
      "labels[0]:\n",
      "itwo, Ojczyzno moja! ty jesteś jak zdrowie; \n",
      "Ile cię trzeba cenić, ten tylko się dowie, \n",
      "Kto cię str\n",
      "\n",
      "samples[1]:\n",
      "racił. Dziś piękność twą w całej ozdobie \n",
      "Widzę i opisuję, bo tęsknię po tobie. \n",
      "Panno święta, co Ja\n",
      "labels[1]:\n",
      "acił. Dziś piękność twą w całej ozdobie \n",
      "Widzę i opisuję, bo tęsknię po tobie. \n",
      "Panno święta, co Jas\n",
      "\n",
      "samples[2]:\n",
      "snej bronisz Częstochowy\n",
      "I w Ostrej świecisz Bramie! Ty, co gród zamkowy \n",
      "Nowogrodzki ochraniasz z j\n",
      "labels[2]:\n",
      "nej bronisz Częstochowy\n",
      "I w Ostrej świecisz Bramie! Ty, co gród zamkowy \n",
      "Nowogrodzki ochraniasz z je\n",
      "\n",
      "samples[3]:\n",
      "ego wiernym ludem! \n",
      "Jak mnie dziecko do zdrowia powróciłaś cudem \n",
      "(Gdy od płaczącej matki pod Twoją \n",
      "labels[3]:\n",
      "go wiernym ludem! \n",
      "Jak mnie dziecko do zdrowia powróciłaś cudem \n",
      "(Gdy od płaczącej matki pod Twoją o\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LEN=100\n",
    "samples = []\n",
    "labels = []\n",
    "for i in range(0,len(dataset_int)-LEN,LEN):\n",
    "    samples.append(dataset_int[i:LEN+i])\n",
    "    labels.append(dataset_int[(i+1):(LEN+i+1)])\n",
    "samples = np.array(samples,dtype=float)\n",
    "labels = np.array(labels,dtype=float)\n",
    "#print(samples[0],'-->',labels[0])\n",
    "for i in range(4):\n",
    "    print('samples[{}]:\\n{}'.format(i,to_text(samples[i])))\n",
    "    print('labels[{}]:\\n{}'.format(i,to_text(labels[i])))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size = 64 - the model expects batches of 64 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           20736     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 81)            83025     \n",
      "=================================================================\n",
      "Total params: 5,350,737\n",
      "Trainable params: 5,350,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(batch_size=1):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Embedding(vocab_size, 256, batch_input_shape=[batch_size, None]))\n",
    "    model.add(LSTM(1024, return_sequences=True,\n",
    "                        stateful=True,#!!!\n",
    "                        recurrent_initializer='glorot_uniform'))\n",
    "    model.add(Dense(vocab_size))\n",
    "    return model  \n",
    "        \n",
    "model = build_model(64)\n",
    "model.summary()\n",
    "\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss)\n",
    "\n",
    "num_epochs = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function that samples *n* random pairs (sample,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def sample_from_dataset(n,samples,labels):\n",
    "    prev_numbers = []\n",
    "    new_samples = []\n",
    "    new_labels = []\n",
    "    while len(new_samples)<n:\n",
    "        number = random.randrange(len(samples))\n",
    "        if number in prev_numbers: continue\n",
    "        prev_numbers.append(number)\n",
    "        new_samples.append(samples[number])\n",
    "        new_labels.append(labels[number])\n",
    "    new_samples = np.array(new_samples,dtype=float)    \n",
    "    new_labels = np.array(new_labels)\n",
    "    return new_samples,new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model (long process...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running...\n",
      "==================================================\n",
      "EPOCH  0\n",
      "==================================================\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3950\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3594\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8931\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0603\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8653\n",
      "\n",
      "Polsko —WAuŚJzteCe,ńrnsjsisi,Ójyowozzztzniezo\n",
      "oNoeod wyiiototnłwAkeuoodionzwuo,eorswk,ynnmsnłm;irłnzupynsąc\n",
      "\n",
      "==================================================\n",
      "EPOCH  5\n",
      "==================================================\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8604\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7848\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6455\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5015\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4483\n",
      "\n",
      "Polsko Rtąyw  ep ó kcąim uDędirwię  ą, ęnnaiw P ewls c,ś  cG ikeóę U?omńzncod Pł   rt s y\n",
      "lłi    cł tNęh.i \n",
      "\n",
      "==================================================\n",
      "EPOCH  10\n",
      "==================================================\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4859\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4388\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3999\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4115\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.4228\n",
      "\n",
      "Polsko bideaniJziiaiła aoz tmha p ecawoashIea \n",
      "ica  łI:ałwei\n",
      "o„owa\n",
      "eeedaóo ,srs \n",
      "tnęłr,nśkza,Kbćł  ióooooa \n",
      "\n",
      "==================================================\n",
      "EPOCH  15\n",
      "==================================================\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3993\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 999us/step - loss: 3.3779\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.3621\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3536\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3499\n",
      "\n",
      "Polsko tw ć, karw mi ynb, wo\n",
      " l n  że tssty kwsz,sąu s i !ey escmy ęie łzeze mipęh diięiżwe sczaw\n",
      "ozsrzoknł\n",
      "\n",
      "==================================================\n",
      "EPOCH  20\n",
      "==================================================\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3557\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.3516\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3430\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3319\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3216\n",
      "\n",
      "Polsko a ami ,d oPpoopmiżiciid tiżi yzSoz p aLdbśhpęęiooakmozddotgr yaitwaeto yy Tdooza ir mtoJżeyjlumwta!d\n",
      "\n",
      "==================================================\n",
      "EPOCH  25\n",
      "==================================================\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3090\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3042\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2994\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2929\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2840\n",
      "\n",
      "Polsko caRew krgs\n",
      "cze \n",
      " \n",
      "taz ysaibniż zidiaaioo w.łmc  zpte wc,aa\n",
      "rz siu)upaewacisić aolooiLi\n",
      "ią.czcwdoapcw\n",
      "\n",
      "==================================================\n",
      "EPOCH  30\n",
      "==================================================\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-dcb049b54f0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# use these samples to train the model in EPOCHS epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mnum_epochs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\programs\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\programs\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\programs\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\programs\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\programs\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\programs\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mC:\\programs\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\programs\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\programs\\miniconda3\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 5 ## much more to get meaningful results...\n",
    "\n",
    "print('running...')\n",
    "for i in range(10): # much more to get meaningful results...\n",
    "    print(50*'=')\n",
    "    print(\"EPOCH \",num_epochs)\n",
    "    print(50*'=')\n",
    "    # randomly choose 64 samples (and labels)\n",
    "    s,l = sample_from_dataset(64,samples,labels)\n",
    "\n",
    "    # use these samples to train the model in EPOCHS epochs\n",
    "    H = model.fit(s,l,epochs=EPOCHS,verbose=1,batch_size=64)\n",
    "    num_epochs += EPOCHS\n",
    "    print()\n",
    "    \n",
    "    # generate the text using the current model\n",
    "    txt = generate_text(model, start_string=\"Polsko \",len=100)\n",
    "    print()\n",
    "    # save the model and weights\n",
    "    #model.save('models/model_{}.h5'.format(num_epochs))\n",
    "    #model.save_weights('weights/weight_{}.h5'.format(num_epochs))\n",
    "print('done!')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generator - generates text using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polsko Umvń)Os„ęsmR“óv(R.;W\n",
      "aŹMęmGDpNdvowńOp!BBm?MRgkŁ\n",
      "’IĆndłŚSŁjźFg’I.éigŻCucą:SŚW“Kx\n",
      "ż\n",
      "ŻyW.P;tÓ,MKUŚRI.óź\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, start_string, len=1000):\n",
    "    print(start_string,end='')\n",
    "     # Convert the start_string to numbers\n",
    "    input_data = [char2idx[s] for s in start_string]\n",
    "    input_data = tf.expand_dims(input_data, 0)\n",
    "\n",
    "    # Empty string to store the results\n",
    "    text_generated = []\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(len):\n",
    "        # the model expects batch of 64 samples so we must produce the batch...\n",
    "        input_data_64 = input_data\n",
    "        for i in range(63):\n",
    "            input_data_64 = np.vstack((input_data_64,input_data))\n",
    "        input_data = input_data_64\n",
    "\n",
    "        predictions = model(input_data)\n",
    "        \n",
    "        # we are interested only in the first prediction\n",
    "        predictions = predictions[0]\n",
    "\n",
    "        # it does NOT work - if we always take max it is easy to have a loop!\n",
    "        # predicted_id = predictions.numpy().argmax(axis=1)[0]\n",
    "\n",
    "        # using a categorical distribution to predict the word returned by the model\n",
    "        #predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    " \n",
    "        # We pass the predicted word as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_data = tf.expand_dims([predicted_id], 0)\n",
    "        print(idx2char[predicted_id],end='')\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "    print()    \n",
    "    return (start_string + ''.join(text_generated))\n",
    "\n",
    "string = \"Polsko \"\n",
    "txt = generate_text(model, start_string=string,len=100)\n",
    "#print(\"Start string: \",string)\n",
    "#print(\"Generated string:\\n>\",txt+\"<\")\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
