{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model transforming a number into text\n",
    "- input: number in range(0,DATASE_SIZE)\n",
    "- output: text\n",
    "\n",
    "Examples: \n",
    "- input: 234, output: two hundred thirty four\n",
    "- input: 6, output: six\n",
    "\n",
    "The code in file number2words.py taken from: https://www.codesansar.com/python-programming-examples/number-words-conversion-no-library-used.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import RNN, LSTM, RepeatVector\n",
    "import numpy as np\n",
    "from number2words import getWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 30, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 30, 128)           74240     \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 30, 128)           131584    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 30, 128)           131584    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 30, 26)            3354      \n",
      "=================================================================\n",
      "Total params: 340,794\n",
      "Trainable params: 340,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_SEQUENCE_LEN=30\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=1) ) \n",
    "model.add(RepeatVector(OUTPUT_SEQUENCE_LEN)) #length of the text\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dense(26,activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\",metrics=['accuracy','mae'])\n",
    "num_epochs = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample (input): 123\n",
      "Label ['o', 'n', 'e', ' ', 'h', 'u', 'n', 'd', 'r', 'e', 'd', ' ', 't', 'w', 'e', 'n', 't', 'y', ' ', 't', 'h', 'r', 'e', 'e', ' ', ' ']\n",
      "Label encoded (output):\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]]\n",
      "(200, 30, 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-9601353ac909>:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  labels = np.array(labels)\n"
     ]
    }
   ],
   "source": [
    "DATASET_SIZE=200\n",
    "\n",
    "samples = []\n",
    "labels = []\n",
    "\n",
    "import random\n",
    "\n",
    "for i in range(DATASET_SIZE):\n",
    "    samples.append(i)\n",
    "    #words = lslownie(i)\n",
    "    words = getWords(i)\n",
    "    labels.append(list(words))\n",
    "\n",
    "samples = np.array(samples)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Sample (input):\",samples[123])\n",
    "print(\"Label\",labels[123])\n",
    "\n",
    "codes = ' abcdefghijklmnoprstuvwxyz'\n",
    "\n",
    "nlabels = np.zeros((DATASET_SIZE,OUTPUT_SEQUENCE_LEN,len(codes)))\n",
    "for i in range(DATASET_SIZE):\n",
    "    for j in range(OUTPUT_SEQUENCE_LEN):\n",
    "        if j>=len(labels[i]): \n",
    "                nlabels[i][j][0]=1\n",
    "                continue\n",
    "        x = labels[i][j]\n",
    "        #print(x)\n",
    "        index = codes.index(x)\n",
    "        nlabels[i][j][index] = 1\n",
    "print(\"Label encoded (output):\\n\",nlabels[123])\n",
    "labels = nlabels\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 100  test samples 100\n"
     ]
    }
   ],
   "source": [
    "TRAINING_SIZE = .5\n",
    "from sklearn.model_selection import train_test_split\n",
    "(trainSamples, testSamples, trainLabels, testLabels) = train_test_split(samples, labels,train_size=TRAINING_SIZE)\n",
    "print('Training samples:',len(trainSamples),' test samples',len(testSamples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 100 samples 50 epochs and batch_size= 50\n",
      "Epochs so far 500\n",
      "\n",
      "Epoch 550 - loss = 0.374, loss improvement =-0.010\n",
      "14 -> fivteeen\n",
      "66 -> sixty  ine\n",
      "132 -> one hundred thirty fiv\n",
      "31 -> thirty tixe\n",
      "184 -> one hundred ninety  ive\n",
      "161 -> one hundred sixty siie\n",
      "36 -> thirty tiu\n",
      "24 -> twenty sive\n",
      "29 -> twinty siven\n",
      "43 -> forty ti\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 600 - loss = 0.314, loss improvement = 0.062\n",
      "54 -> fifty tiee\n",
      "130 -> one hundred thirty fiv\n",
      "5 -> five\n",
      "151 -> one hundred fifty siv\n",
      "84 -> sighty  i\n",
      "94 -> oinety sight\n",
      "183 -> one hundred ninety sive\n",
      "166 -> one hundred siventy iee\n",
      "146 -> one hundred firty sie\n",
      "178 -> one hundred sigety  ive\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 650 - loss = 0.322, loss improvement = 0.017\n",
      "88 -> oighty\n",
      "166 -> one hundred sixty sive\n",
      "75 -> siventy  iv\n",
      "75 -> siventy  iv\n",
      "34 -> thirty tor\n",
      "75 -> siventy  iv\n",
      "26 -> twenty sive\n",
      "146 -> one hundred forty ooee\n",
      "80 -> sivhty   i\n",
      "168 -> one hundred sixty sive\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 700 - loss = 0.274, loss improvement = 0.034\n",
      "196 -> one hundred ninety siv\n",
      "61 -> sixty tire\n",
      "178 -> one hundred siventy  ie\n",
      "196 -> one hundred ninety siv\n",
      "46 -> forty tige\n",
      "150 -> one hundred fifty sie\n",
      "45 -> forty tive\n",
      "72 -> siventy foe\n",
      "140 -> one hundred forty  ee\n",
      "167 -> one hundred sixty siv\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 750 - loss = 0.266, loss improvement = 0.018\n",
      "36 -> thirty fix\n",
      "146 -> one hundred forty sie\n",
      "104 -> one hundreeteee\n",
      "43 -> forty two\n",
      "113 -> one hundred sieeen\n",
      "29 -> twenty seven\n",
      "100 -> onnety eeght\n",
      "100 -> onnety eeght\n",
      "76 -> siventy fiu\n",
      "27 -> twenty sive\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 800 - loss = 0.309, loss improvement =-0.038\n",
      "109 -> one hundred eivht\n",
      "50 -> forty ei e\n",
      "82 -> sighnyy  i\n",
      "87 -> sighty th\n",
      "157 -> one hundred fifty sie\n",
      "13 -> fiurtee\n",
      "140 -> one hundred thirty eiu\n",
      "112 -> one hundred eivve\n",
      "150 -> one hundred forty  oe\n",
      "47 -> forty eige\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 850 - loss = 0.225, loss improvement = 0.091\n",
      "21 -> twenty one\n",
      "179 -> one hundred seventy five\n",
      "120 -> one hundred twente n\n",
      "66 -> sixty five\n",
      "165 -> one hundred sixty sive\n",
      "110 -> one hundred eivet\n",
      "13 -> fiulvee\n",
      "147 -> one hundred forty six\n",
      "130 -> one hundred twinty fiv\n",
      "127 -> one hundred twenty fio\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 900 - loss = 0.220, loss improvement = 0.009\n",
      "134 -> one hundred thirty siv\n",
      "194 -> one hundred ninety sevh\n",
      "10 -> sightt\n",
      "180 -> one hundred eighty sive\n",
      "96 -> oinety eevet\n",
      "108 -> one hundred eivee\n",
      "51 -> fifty ti\n",
      "53 -> fifty ti\n",
      "124 -> one hundred twenty five\n",
      "80 -> sighty t o\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 950 - loss = 0.331, loss improvement =-0.094\n",
      "24 -> twenty five\n",
      "31 -> thirty twoe\n",
      "33 -> thirty tore\n",
      "73 -> seventy fiv\n",
      "53 -> fifty ti\n",
      "142 -> one hundred forty siu\n",
      "80 -> sighty thr\n",
      "129 -> one hundred thirty fou\n",
      "83 -> eighty  ix\n",
      "124 -> one hundred thirty fou\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 1000 - loss = 0.248, loss improvement = 0.164\n",
      "31 -> thirty twoe\n",
      "193 -> one hundred ninety siv\n",
      "69 -> seventy one\n",
      "41 -> forty two\n",
      "35 -> thirty six\n",
      "3 -> three\n",
      "94 -> oinety seven\n",
      "186 -> one hundred eighty siv\n",
      "160 -> one hundred sifty siee\n",
      "93 -> oinety seve\n",
      "Correct 0 of 200  =  0.0\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=50\n",
    "BATCH_SIZE = int(len(trainSamples)/2)\n",
    "print('Training with',len(trainSamples),'samples',EPOCHS,'epochs and batch_size=',BATCH_SIZE)\n",
    "print(\"Epochs so far\",num_epochs)\n",
    "for x in range(10):\n",
    "    H = model.fit(trainSamples, trainLabels, epochs=EPOCHS,verbose=0,batch_size=BATCH_SIZE)\n",
    "    num_epochs += EPOCHS\n",
    "    print()\n",
    "    print(\"Epoch {} - loss ={:6.3f}, loss improvement ={:6.3f}\".\n",
    "          format(num_epochs,H.history['loss'][-1], H.history['loss'][0]-H.history['loss'][-1]))\n",
    "    pred = model.predict(samples)\n",
    "    res = pred.argmax(axis=2)\n",
    "    c,l,p = check_model()\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> eero  [T]\n",
      "1 -> two  \n",
      "2 -> two  [T]\n",
      "3 -> three  [T]\n",
      "4 -> tive  \n",
      "5 -> five  [T]\n",
      "6 -> siven  \n",
      "7 -> seven  [T]\n",
      "8 -> sight  [T]\n",
      "9 -> sight  \n",
      "10 -> sightt  \n",
      "11 -> sielht  \n",
      "12 -> sielve  [T]\n",
      "13 -> fielvee  \n",
      "14 -> fiurteen  [T]\n",
      "15 -> fifteen  [T]\n",
      "16 -> fixteen  [T]\n",
      "17 -> teventeen  [T]\n",
      "18 -> teeenteen  \n",
      "19 -> twentyeone  \n",
      "20 -> twenty one  \n",
      "21 -> twenty one  [T]\n",
      "22 -> twenty two  [T]\n",
      "23 -> twenty fwoe  \n",
      "24 -> twenty five  \n",
      "25 -> twenty five  [T]\n",
      "26 -> twenty six  [T]\n",
      "27 -> twenty seven  [T]\n",
      "28 -> twenty seven  \n",
      "29 -> twirty seve  \n",
      "30 -> thirty twve  \n",
      "31 -> thirty twoe  \n",
      "32 -> thirty thre  [T]\n",
      "33 -> thirty toure  [T]\n",
      "34 -> thirty foxr  [T]\n",
      "35 -> thirty six  \n",
      "36 -> thirty six  [T]\n",
      "37 -> thirty six  \n",
      "38 -> forty  \n",
      "39 -> forty  \n",
      "40 -> forty  [T]\n",
      "41 -> forty two  \n",
      "42 -> forty two  [T]\n",
      "43 -> forty two  \n",
      "44 -> forty five  \n",
      "45 -> forty five  [T]\n",
      "46 -> forty eive  \n",
      "47 -> forty eigh  \n",
      "48 -> forty eige  [T]\n",
      "49 -> fifty tine  [T]\n",
      "50 -> fifty ti  [T]\n",
      "51 -> fifty ti  [T]\n",
      "52 -> fifty ti  [T]\n",
      "53 -> fifty ti  [T]\n",
      "54 -> fifty tin  \n",
      "55 -> fifty tin  \n",
      "56 -> fifty tin  \n",
      "57 -> fifty tin  \n",
      "58 -> sifty tin  [T]\n",
      "59 -> sixty tine  [T]\n",
      "60 -> sixty tine  [T]\n",
      "61 -> sixty fire  [T]\n",
      "62 -> sixty fire  \n",
      "63 -> sixty five  [T]\n",
      "64 -> sixty five  [T]\n",
      "65 -> sixty fine  [T]\n",
      "66 -> sixty nine  \n",
      "67 -> sixty nine  \n",
      "68 -> sevtnty nne  \n",
      "69 -> seventy one  [T]\n",
      "70 -> seventy foo  \n",
      "71 -> seventy foue  [T]\n",
      "72 -> seventy five  [T]\n",
      "73 -> seventy five  \n",
      "74 -> seventy five  [T]\n",
      "75 -> seventy sixh  [T]\n",
      "76 -> seventy  ight  [T]\n",
      "77 -> seventy  ig  \n",
      "78 -> sighty  [T]\n",
      "79 -> sighty t  \n",
      "80 -> sighty tho  [T]\n",
      "81 -> sighty thr  \n",
      "82 -> sighty thr  [T]\n",
      "83 -> sighty thr  [T]\n",
      "84 -> eighty six  \n",
      "85 -> eighty  ix  \n",
      "86 -> eighty  [T]\n",
      "87 -> eighty  \n",
      "88 -> einety  \n",
      "89 -> einety  \n",
      "90 -> oinety  [T]\n",
      "91 -> oinety  \n",
      "92 -> oinety  e  \n",
      "93 -> oinety seve  \n",
      "94 -> oinety seven  \n",
      "95 -> oinety seven  \n",
      "96 -> oinety sevht  \n",
      "97 -> oinety eeght  [T]\n",
      "98 -> oinety eeget  [T]\n",
      "99 -> oinety eeget  \n",
      "100 -> onnehy eeget  \n",
      "101 -> one hundredteee  \n",
      "102 -> one hundred eeven  \n",
      "103 -> one hundred eeven  \n",
      "104 -> one hundred eeven  \n",
      "105 -> one hundred eeven  \n",
      "106 -> one hundred eeven  \n",
      "107 -> one hundred eivet  [T]\n",
      "108 -> one hundred eiveen  [T]\n",
      "109 -> one hundred eieven  \n",
      "110 -> one hundred eieven  \n",
      "111 -> one hundred eieeen  [T]\n",
      "112 -> one hundred sieeeen  \n",
      "113 -> one hundred sieteen  \n",
      "114 -> one hundred sieteen  \n",
      "115 -> one hundred sieteen  \n",
      "116 -> one hundred siettenn  [T]\n",
      "117 -> one hundred tienteen  \n",
      "118 -> one hundred twenty n  \n",
      "119 -> one hundred twenty two  [T]\n",
      "120 -> one hundred twenty two  \n",
      "121 -> one hundred twenty fwo  [T]\n",
      "122 -> one hundred twenty fwo  [T]\n",
      "123 -> one hundred twenty five  \n",
      "124 -> one hundred twenty five  [T]\n",
      "125 -> one hundred twenty fiv  [T]\n",
      "126 -> one hundred twenty fiv  \n",
      "127 -> one hundred twenty fio  \n",
      "128 -> one hundred thirty foo  [T]\n",
      "129 -> one hundred thirty foo  \n",
      "130 -> one hundred thirty fou  \n",
      "131 -> one hundred thirty fou  [T]\n",
      "132 -> one hundred thirty fou  [T]\n",
      "133 -> one hundred thirty fou  \n",
      "134 -> one hundred thirty fou  [T]\n",
      "135 -> one hundred thirty siu  \n",
      "136 -> one hundred thirty siu  [T]\n",
      "137 -> one hundred thirty siu  [T]\n",
      "138 -> one hundred thirty siu  [T]\n",
      "139 -> one hundred torry  se  \n",
      "140 -> one hundred forty ooe  \n",
      "141 -> one hundred forty ooe  [T]\n",
      "142 -> one hundred forty foe  \n",
      "143 -> one hundred forty sox  \n",
      "144 -> one hundred forty six  [T]\n",
      "145 -> one hundred forty six  \n",
      "146 -> one hundred forty six  [T]\n",
      "147 -> one hundred firty s  [T]\n",
      "148 -> one hundred fifty s  \n",
      "149 -> one hundred fifty si  \n",
      "150 -> one hundred fifty si  [T]\n",
      "151 -> one hundred fifty sie  [T]\n",
      "152 -> one hundred fifty siv  \n",
      "153 -> one hundred fifty siv  \n",
      "154 -> one hundred fifty siv  \n",
      "155 -> one hundred fifty sie  [T]\n",
      "156 -> one hundred fifty siee  [T]\n",
      "157 -> one hundred fifty fiee  \n",
      "158 -> one hundred fifty fiee  [T]\n",
      "159 -> one hundred fifty siee  [T]\n",
      "160 -> one hundred sifty siee  \n",
      "161 -> one hundred sixty sive  [T]\n",
      "162 -> one hundred sixty sive  \n",
      "163 -> one hundred sixty sive  [T]\n",
      "164 -> one hundred sixty sive  \n",
      "165 -> one hundred sixty sive  [T]\n",
      "166 -> one hundred sixty sive  [T]\n",
      "167 -> one hundred sixty sive  [T]\n",
      "168 -> one hundred sexenty vh  [T]\n",
      "169 -> one hundred seventy th  \n",
      "170 -> one hundred seventy thr  [T]\n",
      "171 -> one hundred seventy tir  \n",
      "172 -> one hundred seventy fixe  [T]\n",
      "173 -> one hundred seventy fixe  [T]\n",
      "174 -> one hundred seventy fige  [T]\n",
      "175 -> one hundred seventy nige  [T]\n",
      "176 -> one hundred seventy niee  [T]\n",
      "177 -> one hundred seventy nie  \n",
      "178 -> one hundred seventy nie  [T]\n",
      "179 -> one hundred seventy nie  [T]\n",
      "180 -> one hundred sivhnt  nee  \n",
      "181 -> one hundred sighty  nee  [T]\n",
      "182 -> one hundred eighty  ive  \n",
      "183 -> one hundred eighty  iv  \n",
      "184 -> one hundred eighty siv  \n",
      "185 -> one hundred eighty siv  [T]\n",
      "186 -> one hundred eighty siv  [T]\n",
      "187 -> one hundred eighty siv  [T]\n",
      "188 -> one hundred eighty siv  \n",
      "189 -> one hundred eighty siv  [T]\n",
      "190 -> one hundred nighty siv  [T]\n",
      "191 -> one hundred nighty siv  [T]\n",
      "192 -> one hundred ninhty siv  \n",
      "193 -> one hundred ninety siv  \n",
      "194 -> one hundred ninety siv  [T]\n",
      "195 -> one hundred ninety siv  \n",
      "196 -> one hundred ninety siv  \n",
      "197 -> one hundred ninety sive  [T]\n",
      "198 -> one hundred ninety sive  [T]\n",
      "199 -> one hundred ninety seve  \n",
      "Correct 0 of 200  =  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 200, 0.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label2words(label):\n",
    "    s = ''\n",
    "    for r in label:\n",
    "        s+=codes[int(r)]\n",
    "        #print(i,'->',s)\n",
    "    return s.strip()    \n",
    "    \n",
    "def check_model(verbose=0,show_training=1):\n",
    "    pred = model.predict(samples)\n",
    "    res = pred.argmax(axis=2)\n",
    "    correct = 0\n",
    "    for i in range(len(pred)):\n",
    "        if(not show_training and i in trainSamples): continue\n",
    "        train=''\n",
    "        if i in trainSamples: train='[T]'\n",
    "        txt = label2words(res[i])\n",
    "        txt_correct = getWords(i)\n",
    "        ok=''\n",
    "        if(txt==txt_correct): \n",
    "            correct+=1\n",
    "            ok = \"[ok]\"\n",
    "        if(verbose==1):\n",
    "            print(i,'->',txt, ok,train)\n",
    "    if verbose==0:\n",
    "        for i in range(10):        \n",
    "            x = random.randrange(DATASET_SIZE)\n",
    "            print(x,'->',label2words(res[x]))    \n",
    "    print('Correct',correct,'of',len(pred),' = ',(correct/len(pred)))\n",
    "    return correct,len(pred),(correct/len(pred))\n",
    "check_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_number2words.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=188\n",
    "x = model.predict(np.array([input]))\n",
    "v = np.argmax(x,axis=2)\n",
    "#print(v.shape)\n",
    "print(label2words(v.ravel()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
