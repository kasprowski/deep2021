{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model transforming a number into text\n",
    "- input: number in range(0,DATASE_SIZE)\n",
    "- output: text\n",
    "\n",
    "Examples: \n",
    "- input: 234, output: dwieście trzydzieści cztery\n",
    "- input: 6, output: sześć\n",
    "\n",
    "The file kwotaslownie.py taken from: https://github.com/dowgird/pyliczba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import RNN, LSTM, RepeatVector\n",
    "import numpy as np\n",
    "from kwotaslownie import lslownie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 30, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 30, 128)           74240     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 128)           131584    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 30, 128)           131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30, 33)            4257      \n",
      "=================================================================\n",
      "Total params: 341,697\n",
      "Trainable params: 341,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_SEQUENCE_LEN=30\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=1) ) \n",
    "model.add(RepeatVector(OUTPUT_SEQUENCE_LEN)) #length of the text\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dense(33,activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\",metrics=['accuracy','mae'])\n",
    "num_epochs = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample (input): 0\n",
      "Label ['z', 'e', 'r', 'o']\n",
      "Label encoded (output):\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "(200, 30, 33)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-6703fd855143>:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  labels = np.array(labels)\n"
     ]
    }
   ],
   "source": [
    "DATASET_SIZE=200\n",
    "\n",
    "samples = []\n",
    "labels = []\n",
    "\n",
    "import random\n",
    "\n",
    "for i in range(DATASET_SIZE):\n",
    "    samples.append(i)\n",
    "    words = lslownie(i)\n",
    "    labels.append(list(words))\n",
    "\n",
    "samples = np.array(samples)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Sample (input):\",samples[0])\n",
    "print(\"Label\",labels[0])\n",
    "\n",
    "codes = ' aąbcćdeęfghijklłmnńoóprsśtuwyzżź'\n",
    "\n",
    "nlabels = np.zeros((DATASET_SIZE,OUTPUT_SEQUENCE_LEN,len(codes)))\n",
    "for i in range(DATASET_SIZE):\n",
    "    for j in range(OUTPUT_SEQUENCE_LEN):\n",
    "        if j>=len(labels[i]): \n",
    "                nlabels[i][j][0]=1\n",
    "                continue\n",
    "        x = labels[i][j]\n",
    "        index = codes.index(x)\n",
    "        nlabels[i][j][index] = 1\n",
    "print(\"Label encoded (output):\\n\",nlabels[123])\n",
    "labels = nlabels\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 100  test samples 100\n"
     ]
    }
   ],
   "source": [
    "TRAINING_SIZE = .5\n",
    "from sklearn.model_selection import train_test_split\n",
    "(trainSamples, testSamples, trainLabels, testLabels) = train_test_split(samples, labels,train_size=TRAINING_SIZE)\n",
    "print('Training samples:',len(trainSamples),' test samples',len(testSamples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 100 samples 50 epochs and batch_size= 50\n",
      "Epochs so far 550\n",
      "\n",
      "Epoch 600 - loss = 0.605, loss improvement = 0.015\n",
      "137 -> sto cztddzieści dzieei\n",
      "129 -> sto dwadzieścia dzeew\n",
      "105 -> sto dii\n",
      "27 -> twadzieścia pzećć\n",
      "178 -> sto sziemdzieesiąt  z\n",
      "Correct 2 of 200  =  0.01\n",
      "\n",
      "Epoch 650 - loss = 0.597, loss improvement =-0.011\n",
      "62 -> sześćdziesąąt\n",
      "172 -> sto szeećdziesiąt\n",
      "186 -> sto sziemdziesiąt   e\n",
      "51 -> czterdzieści szieei ć\n",
      "128 -> sto dwadzieścia jzee\n",
      "Correct 2 of 200  =  0.01\n",
      "\n",
      "Epoch 700 - loss = 0.530, loss improvement = 0.080\n",
      "6 -> dster\n",
      "157 -> sto szeććdziesiąt  zee\n",
      "94 -> ssiewięćdziesiąt czeery\n",
      "130 -> sto trzddzieści dzeew\n",
      "177 -> sto sziemmziessiąt  zee\n",
      "Correct 5 of 200  =  0.025\n",
      "\n",
      "Epoch 750 - loss = 0.652, loss improvement =-0.057\n",
      "35 -> trzydzieści dzee\n",
      "140 -> sto crtydzieści dziew\n",
      "167 -> sto sześćdziesiąt  zte\n",
      "92 -> ssiemdziesiąt sziewi\n",
      "102 -> sto wię             e\n",
      "Correct 5 of 200  =  0.025\n",
      "\n",
      "Epoch 800 - loss = 0.543, loss improvement = 0.142\n",
      "111 -> sto dzienaście\n",
      "182 -> sto osiemdziesiąt  z e\n",
      "22 -> dwadzieścia\n",
      "166 -> sto sześćdziesiąt   ze\n",
      "159 -> sto sześćdziesiąt  z\n",
      "Correct 6 of 200  =  0.03\n",
      "\n",
      "Epoch 850 - loss = 0.532, loss improvement = 0.027\n",
      "186 -> sto osiemdęćeziesiąt e\n",
      "32 -> trzydzieści\n",
      "145 -> sto czterdzieści  ziee\n",
      "170 -> sto szeemmdziesiąt\n",
      "34 -> trzydzieści dwze\n",
      "Correct 4 of 200  =  0.02\n",
      "\n",
      "Epoch 900 - loss = 0.401, loss improvement = 0.126\n",
      "9 -> dsiem\n",
      "158 -> sto szećdziesiąt  rze\n",
      "41 -> tzterdzieści  wa\n",
      "82 -> ssiemdziesiąt  zeem\n",
      "70 -> sieśćmziesiąt  ziś\n",
      "Correct 9 of 200  =  0.045\n",
      "\n",
      "Epoch 950 - loss = 0.516, loss improvement =-0.100\n",
      "54 -> częerdzieśii szieeięć\n",
      "196 -> sto osiewięćdziesiąt sziść\n",
      "138 -> sto cztyddiieści siee\n",
      "39 -> trzydzieeci  ziewięć\n",
      "127 -> sto dwadzieścia jzeen\n",
      "Correct 5 of 200  =  0.025\n",
      "\n",
      "Epoch 1000 - loss = 0.401, loss improvement = 0.078\n",
      "77 -> sseemmdziesiąt dzeeć\n",
      "160 -> sto sześćdziesiąt czte\n",
      "74 -> siedemdziesiąt dwa\n",
      "182 -> sto osiemdziesiąt szee\n",
      "104 -> sto driem\n",
      "Correct 15 of 200  =  0.075\n",
      "\n",
      "Epoch 1050 - loss = 0.337, loss improvement = 0.092\n",
      "94 -> ssiewięćdziesiąt dztery\n",
      "31 -> trzydzieści de e\n",
      "144 -> sto czterdzieści citew\n",
      "196 -> sto osiewięćdziesiąt sześ\n",
      "171 -> sto sieśćddziesiąt czee\n",
      "Correct 15 of 200  =  0.075\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=50\n",
    "BATCH_SIZE = int(len(trainSamples)/2)\n",
    "print('Training with',len(trainSamples),'samples',EPOCHS,'epochs and batch_size=',BATCH_SIZE)\n",
    "print(\"Epochs so far\",num_epochs)\n",
    "for x in range(10):\n",
    "    H = model.fit(trainSamples, trainLabels, epochs=EPOCHS,verbose=0,batch_size=BATCH_SIZE)\n",
    "    num_epochs += EPOCHS\n",
    "    print()\n",
    "    print(\"Epoch {} - loss ={:6.3f}, loss improvement ={:6.3f}\".\n",
    "          format(num_epochs,H.history['loss'][-1], H.history['loss'][0]-H.history['loss'][-1]))\n",
    "    pred = model.predict(samples)\n",
    "    res = pred.argmax(axis=2)\n",
    "    c,l,p = check_model()\n",
    "#    print(\"accuracy={:6.3f}%\".format(100*p))\n",
    "#     f = open(\"output.txt\", \"a\")\n",
    "#     f.write(\"=================================================================================\\n\")\n",
    "#     f.write(\"{} Epoch {} - loss ={:6.3f}, loss improvement ={:6.3f}\\n\".\n",
    "#             format(i,num_epochs,H.history['loss'][-1], H.history['loss'][0]-H.history['loss'][-1]))\n",
    "#     f.write(\"accuracy={:6.3f}%\\n\".format(100*p))\n",
    "#     for i in range(len(pred)):\n",
    "#         txt = label2words(res[i])\n",
    "#         f.write(\"{} -> {}\\n\".format(i,txt))\n",
    "#     f.close()\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> jero  [T]\n",
      "1 -> jeden [ok] [T]\n",
      "2 -> jrden  \n",
      "3 -> trzy [ok] [T]\n",
      "4 -> tztery  [T]\n",
      "5 -> cztery  \n",
      "6 -> cster  \n",
      "7 -> osiem  \n",
      "8 -> osiem [ok] [T]\n",
      "9 -> dsiem  \n",
      "10 -> dsienaści  \n",
      "11 -> dwdenaście  [T]\n",
      "12 -> dwanaście [ok] [T]\n",
      "13 -> deanaście  \n",
      "14 -> deennaście  \n",
      "15 -> deeennaście  \n",
      "16 -> diedemaaścee  \n",
      "17 -> diedemnaście  [T]\n",
      "18 -> dwedeeenście  \n",
      "19 -> dwadzieścia  \n",
      "20 -> dwadzieścia [ok] [T]\n",
      "21 -> dwadzieścia  \n",
      "22 -> dwadzieścia trzy  \n",
      "23 -> dwadzieścia trzy [ok] [T]\n",
      "24 -> dwadzieścia cztery [ok] [T]\n",
      "25 -> dwadzieścia pięćć  [T]\n",
      "26 -> dwadzieścia sześć [ok] [T]\n",
      "27 -> dwadzieścia dzeewięć  \n",
      "28 -> twadzieścia dzeewięć  \n",
      "29 -> twadzieścia dziewięć  [T]\n",
      "30 -> trzydzieści    e  [T]\n",
      "31 -> trzydzieści de e  [T]\n",
      "32 -> trzydzieści dway  [T]\n",
      "33 -> trzydzieści tray  [T]\n",
      "34 -> trzydzieści tray  \n",
      "35 -> trzydzieści pzęć  [T]\n",
      "36 -> trzydzieści siećć  [T]\n",
      "37 -> trzydzieści szeeć  [T]\n",
      "38 -> trzydzieści szeewięć  \n",
      "39 -> trzydzieści dziewięć [ok] [T]\n",
      "40 -> tzterdzieści  i  [T]\n",
      "41 -> czterdzieści  wa  \n",
      "42 -> czterdzieści dwa [ok] [T]\n",
      "43 -> czterdzieści cwa  \n",
      "44 -> czterdzieści pztć  [T]\n",
      "45 -> czterdzieści pześ  [T]\n",
      "46 -> czterdzieści sześć [ok] [T]\n",
      "47 -> czterdzieści sziść  \n",
      "48 -> czterdzieści dziemię  [T]\n",
      "49 -> czterdzieści dziewięć [ok] [T]\n",
      "50 -> czterdzieści oziewięć  \n",
      "51 -> czterdzieści sziewięć  \n",
      "52 -> czterdzieści sziewięć  \n",
      "53 -> cztćrzzeeśii sieewięć  \n",
      "54 -> częćdzieeiit sieeem  \n",
      "55 -> częćdziesiąt sieeem  \n",
      "56 -> częćdziesiąt siedem  \n",
      "57 -> czeććziesiąt siedem  [T]\n",
      "58 -> sześćziesiąt s edem  \n",
      "59 -> sześćdzesiąt  \n",
      "60 -> sześćdziesiąt [ok] [T]\n",
      "61 -> sześćdziesiąt  wa  \n",
      "62 -> sześćdziesiąt dra  [T]\n",
      "63 -> sześćdziesiąt dray  [T]\n",
      "64 -> sześćdziesiąt szay  \n",
      "65 -> sześćdziesiąt sześć  \n",
      "66 -> sześćdziesiąt sziść  [T]\n",
      "67 -> sześćdziesiąt sziść  \n",
      "68 -> sieśćdziesiąt sziem  [T]\n",
      "69 -> siedćmdziesiąt  i  \n",
      "70 -> siedemdziesiąt dw  [T]\n",
      "71 -> siedemdziesiąt dwa  \n",
      "72 -> siedemdziesiąt dwa [ok] [T]\n",
      "73 -> siedemdziesiąt dwa  \n",
      "74 -> siedemdziesiąt dw  \n",
      "75 -> siedemdziesiąt dweś  \n",
      "76 -> siedemdziesiąt dześ  [T]\n",
      "77 -> siedemdziesiąt dz ś  \n",
      "78 -> siedemdziesiąt dzee  \n",
      "79 -> sseeemdziesiąt dzeew ę  [T]\n",
      "80 -> ssiemmdiiesią  dzee  [T]\n",
      "81 -> ssiemdziesiąt   zee  [T]\n",
      "82 -> ssiemdziesiąt  zzen  \n",
      "83 -> ssiemdziesiąt jzten  \n",
      "84 -> ssiemdziesiąt szter  [T]\n",
      "85 -> ssiemdziesiąt szeeć  \n",
      "86 -> ssiemdziesiąt szieć  [T]\n",
      "87 -> ssiemdziesiąt szieć  \n",
      "88 -> ssiemdziesiąt dziew  [T]\n",
      "89 -> ssiemdziesiąt dziewi  [T]\n",
      "90 -> ssiemdziesiąt dziewięć  \n",
      "91 -> ssiewięćdziesiązedwi  \n",
      "92 -> ssiewięćdziesiąt dwa  [T]\n",
      "93 -> ssiewięćdziesiąt dwae  \n",
      "94 -> ssiewięćdziesiąt dztery  [T]\n",
      "95 -> ssiewięćdziesiąt cztery  \n",
      "96 -> ssiewięćdziesiąt cztery  \n",
      "97 -> stiewięćdziesiąt szeeem  [T]\n",
      "98 -> stiewięćdziesiąt siedem  \n",
      "99 -> sto wi  dziesiąt siedem  \n",
      "100 -> sto [ok] [T]\n",
      "101 -> sto d  \n",
      "102 -> sto di  [T]\n",
      "103 -> sto dr y  [T]\n",
      "104 -> sto driy  \n",
      "105 -> sto dree  \n",
      "106 -> sto dree  \n",
      "107 -> sto dzeem  [T]\n",
      "108 -> sto dziemm  [T]\n",
      "109 -> sto dziena  [T]\n",
      "110 -> sto dzienaśc  \n",
      "111 -> sto dzienaści  [T]\n",
      "112 -> sto dzienaście  [T]\n",
      "113 -> sto diienaście  [T]\n",
      "114 -> sto diienaście  [T]\n",
      "115 -> sto diienaaście  [T]\n",
      "116 -> sto diaennaście  \n",
      "117 -> sto dwaennaście  [T]\n",
      "118 -> sto dwaemiaście  [T]\n",
      "119 -> sto dwadzieścia  e  [T]\n",
      "120 -> sto dwadzieścia jea  \n",
      "121 -> sto dwadzieścia jea  [T]\n",
      "122 -> sto dwadzieścia jeae  [T]\n",
      "123 -> sto dwadzieścia jeae  \n",
      "124 -> sto dwadzieścia dzeeć  \n",
      "125 -> sto dwadzieścia szeeć  \n",
      "126 -> sto dwadzieścia szeen  [T]\n",
      "127 -> sto dwadzieścia szeen  \n",
      "128 -> sto dwadzieścia jzeeni  \n",
      "129 -> sto tradzieścia jzeeni  [T]\n",
      "130 -> sto trzddieścia jzeeni  \n",
      "131 -> sto trzddzieści jzeer  [T]\n",
      "132 -> sto trzydzieści jzter  \n",
      "133 -> sto trzydzieści jzter  \n",
      "134 -> sto trzydzieści pzter  [T]\n",
      "135 -> sto trzydzieści pztery  [T]\n",
      "136 -> sto trzydzieści pztewy  \n",
      "137 -> sto trzydzieści dztewi  \n",
      "138 -> sto trtydzieści dziewi  \n",
      "139 -> sto trtydzieści dziewi  [T]\n",
      "140 -> sto czteddieści  zieei  \n",
      "141 -> sto czterdiieści sieei  [T]\n",
      "142 -> sto czterdzieści sieew  \n",
      "143 -> sto czterdzieści sitew  \n",
      "144 -> sto czterdzieści citew  [T]\n",
      "145 -> sto czterdzieści citew  [T]\n",
      "146 -> sto czterdzieści citew  \n",
      "147 -> sto czterdzieści czier  [T]\n",
      "148 -> sto czterdzieści dzier  [T]\n",
      "149 -> sto czterdzieści czier  [T]\n",
      "150 -> sto cztćrzzeeici ozier  [T]\n",
      "151 -> sto częćdziesiąt ozier  \n",
      "152 -> sto częćdziesiąt czter  \n",
      "153 -> sto pzęćdziesiąt czter  [T]\n",
      "154 -> sto pzęćdziesiąt crter  [T]\n",
      "155 -> sto szęćdziesiąt orter  \n",
      "156 -> sto szęćdziesiąt orter  \n",
      "157 -> sto szećdziesiąt  ster  \n",
      "158 -> sto szećdziesiąt  sze  [T]\n",
      "159 -> sto szeććdzesiątt sze  \n",
      "160 -> sto sześćdziesiąt see  [T]\n",
      "161 -> sto sześćdziesiąt sede  [T]\n",
      "162 -> sto sześćdziesiąt cete  [T]\n",
      "163 -> sto sześćdziesiąt crte  [T]\n",
      "164 -> sto sześćdziesiąt czter  [T]\n",
      "165 -> sto sześćdziesiąt czter  \n",
      "166 -> sto sieśćdziesiąt czter  \n",
      "167 -> sto sieśćdziesiąt  zter  \n",
      "168 -> sto sieśćdziesiąt  sze  [T]\n",
      "169 -> sto sieśćddiessiąt sze  \n",
      "170 -> sto sieśćddziesiąt szee  [T]\n",
      "171 -> sto sieśćddziesiąt czee  [T]\n",
      "172 -> sto siedemdziesiąt czte  \n",
      "173 -> sto siedemdziesiąt czte  \n",
      "174 -> sto siedemdziesiąt czte  [T]\n",
      "175 -> sto szeeemdziesiąt czte  [T]\n",
      "176 -> sto szeeemdziesiąt czte  \n",
      "177 -> sto szeemmdziesiąt czte  \n",
      "178 -> sto sziemmdziesiąt  zee  \n",
      "179 -> sto osiemmzieesąt   ze  \n",
      "180 -> sto osiemdziesiąt  rze  [T]\n",
      "181 -> sto osiemdziesiąt  rze  [T]\n",
      "182 -> sto osiemdziesiąt sree  \n",
      "183 -> sto osiemdziesiąt szee  [T]\n",
      "184 -> sto osiemdziesiąt szee  \n",
      "185 -> sto osiemdziesiąt szee  \n",
      "186 -> sto osiemdziesiąt szee  [T]\n",
      "187 -> sto osiemdziesiąt szee  [T]\n",
      "188 -> sto osiemdziesiąt szee  [T]\n",
      "189 -> sto osiemdziesiąt ątid  \n",
      "190 -> sto osiewdęćdziąsiąt de  [T]\n",
      "191 -> sto osiewięćdziesiąt dr  \n",
      "192 -> sto osiewięćdziesiąt dr  [T]\n",
      "193 -> sto osiewięćdziesiąt dra  [T]\n",
      "194 -> sto osiewięćdziesiąt szz  \n",
      "195 -> sto osiewięćdziesiąt szzś  \n",
      "196 -> sto osiewięćdziesiąt sześ  [T]\n",
      "197 -> sto osiewięćdziesiąt sześć  \n",
      "198 -> sto osiewięćdziesiąt sześć  \n",
      "199 -> sto osiewięćdziesiąt sześć  \n",
      "Correct 15 of 200  =  0.075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15, 200, 0.075)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label2words(label):\n",
    "    s = ''\n",
    "    for r in label:\n",
    "        s+=codes[int(r)]\n",
    "        #print(i,'->',s)\n",
    "    return s.strip()    \n",
    "    \n",
    "def check_model(verbose=0,show_training=1):\n",
    "    pred = model.predict(samples)\n",
    "    res = pred.argmax(axis=2)\n",
    "    correct = 0\n",
    "    for i in range(len(pred)):\n",
    "        if(not show_training and i in trainSamples): continue\n",
    "        train=''\n",
    "        if i in trainSamples: train='[T]'\n",
    "        txt = label2words(res[i])\n",
    "        txt_correct = lslownie(i)\n",
    "        ok=''\n",
    "        if(txt==txt_correct): \n",
    "            correct+=1\n",
    "            ok = \"[ok]\"\n",
    "        if(verbose==1):\n",
    "            print(i,'->',txt, ok,train)\n",
    "    if verbose==0:\n",
    "        for i in range(5):        \n",
    "            x = random.randrange(DATASET_SIZE)\n",
    "            print(x,'->',label2words(res[x]))    \n",
    "    print('Correct',correct,'of',len(pred),' = ',(correct/len(pred)))\n",
    "    return correct,len(pred),(correct/len(pred))\n",
    "check_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_number2words.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=188\n",
    "x = model.predict(np.array([input]))\n",
    "v = np.argmax(x,axis=2)\n",
    "#print(v.shape)\n",
    "print(label2words(v.ravel()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
