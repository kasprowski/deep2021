{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 2,851\n",
      "Trainable params: 2,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=4, activation='sigmoid'))\n",
    "model.add(Dense(50, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "##model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data (and remove one class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 150\n",
      "Rows after removal of 'Iris-virginica': 100\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('iris.data')\n",
    "print(\"Rows:\",len(data))\n",
    "data = data.drop(data[data.iris=='Iris-virginica'].index)\n",
    "print(\"Rows after removal of 'Iris-virginica':\",len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare samples and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: {'Iris-versicolor', 'Iris-setosa'}\n",
      "Classes after renaming: {0.0, 1.0}\n",
      "Samples: (100, 4)\n",
      "Labels: (100,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes:\",set(data['iris']))\n",
    "samples = data.to_numpy()[:,:4]\n",
    "samples = samples.astype(float)\n",
    "labels = data.to_numpy()[:,4]\n",
    "\n",
    "labels[labels[:]=='Iris-versicolor']=0\n",
    "labels[labels[:]=='Iris-setosa']=1\n",
    "#labels[labels[:]=='Iris-virginica']=2\n",
    "labels = labels.astype(float)\n",
    "print(\"Classes after renaming:\",set(labels))\n",
    "\n",
    "print(\"Samples:\",samples.shape)\n",
    "print(\"Labels:\",labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "(trainSamples, testSamples, trainLabels, testLabels) = sklearn.model_selection.train_test_split(samples, labels, random_state=1)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "8/8 [==============================] - 0s 880us/step - loss: 0.6947 - accuracy: 0.5333\n",
      "Epoch 2/40\n",
      "8/8 [==============================] - 0s 750us/step - loss: 0.6784 - accuracy: 0.5467\n",
      "Epoch 3/40\n",
      "8/8 [==============================] - 0s 750us/step - loss: 0.6705 - accuracy: 0.9333\n",
      "Epoch 4/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6531 - accuracy: 0.9733\n",
      "Epoch 5/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6385 - accuracy: 0.7333\n",
      "Epoch 6/40\n",
      "8/8 [==============================] - 0s 999us/step - loss: 0.6266 - accuracy: 0.6267\n",
      "Epoch 7/40\n",
      "8/8 [==============================] - 0s 1000us/step - loss: 0.6102 - accuracy: 0.7867\n",
      "Epoch 8/40\n",
      "8/8 [==============================] - 0s 1000us/step - loss: 0.5920 - accuracy: 0.9600\n",
      "Epoch 9/40\n",
      "8/8 [==============================] - 0s 999us/step - loss: 0.5747 - accuracy: 0.9467\n",
      "Epoch 10/40\n",
      "8/8 [==============================] - 0s 996us/step - loss: 0.5532 - accuracy: 0.9600\n",
      "Epoch 11/40\n",
      "8/8 [==============================] - 0s 999us/step - loss: 0.5319 - accuracy: 1.0000\n",
      "Epoch 12/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5079 - accuracy: 1.0000\n",
      "Epoch 13/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4838 - accuracy: 1.0000\n",
      "Epoch 14/40\n",
      "8/8 [==============================] - 0s 875us/step - loss: 0.4553 - accuracy: 1.0000\n",
      "Epoch 15/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 1.0000\n",
      "Epoch 16/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3998 - accuracy: 1.0000\n",
      "Epoch 17/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3699 - accuracy: 1.0000\n",
      "Epoch 18/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3425 - accuracy: 1.0000\n",
      "Epoch 19/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3109 - accuracy: 1.0000\n",
      "Epoch 20/40\n",
      "8/8 [==============================] - 0s 879us/step - loss: 0.2824 - accuracy: 1.0000\n",
      "Epoch 21/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2556 - accuracy: 1.0000\n",
      "Epoch 22/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2309 - accuracy: 1.0000\n",
      "Epoch 23/40\n",
      "8/8 [==============================] - 0s 877us/step - loss: 0.2071 - accuracy: 1.0000\n",
      "Epoch 24/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 1.0000\n",
      "Epoch 25/40\n",
      "8/8 [==============================] - 0s 875us/step - loss: 0.1671 - accuracy: 1.0000\n",
      "Epoch 26/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1500 - accuracy: 1.0000\n",
      "Epoch 27/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1357 - accuracy: 1.0000\n",
      "Epoch 28/40\n",
      "8/8 [==============================] - 0s 750us/step - loss: 0.1223 - accuracy: 1.0000\n",
      "Epoch 29/40\n",
      "8/8 [==============================] - 0s 1000us/step - loss: 0.1106 - accuracy: 1.0000\n",
      "Epoch 30/40\n",
      "8/8 [==============================] - 0s 999us/step - loss: 0.0999 - accuracy: 1.0000\n",
      "Epoch 31/40\n",
      "8/8 [==============================] - 0s 875us/step - loss: 0.0920 - accuracy: 1.0000\n",
      "Epoch 32/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0839 - accuracy: 1.0000\n",
      "Epoch 33/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0762 - accuracy: 1.0000\n",
      "Epoch 34/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 1.0000\n",
      "Epoch 35/40\n",
      "8/8 [==============================] - 0s 873us/step - loss: 0.0647 - accuracy: 1.0000\n",
      "Epoch 36/40\n",
      "8/8 [==============================] - 0s 1000us/step - loss: 0.0599 - accuracy: 1.0000\n",
      "Epoch 37/40\n",
      "8/8 [==============================] - 0s 875us/step - loss: 0.0554 - accuracy: 1.0000\n",
      "Epoch 38/40\n",
      "8/8 [==============================] - 0s 875us/step - loss: 0.0515 - accuracy: 1.0000\n",
      "Epoch 39/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0481 - accuracy: 1.0000\n",
      "Epoch 40/40\n",
      "8/8 [==============================] - 0s 875us/step - loss: 0.0450 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(trainSamples, trainLabels, epochs=40,batch_size=10)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0545657  0.03043625 0.9816704  0.06678402 0.09936816 0.96699595\n",
      "  0.9733919  0.05569908 0.05266124 0.03783125 0.04681817 0.9633428\n",
      "  0.02854529 0.0236502  0.03404835 0.98010814 0.95450854 0.94450945\n",
      "  0.02871946 0.9711163  0.9665257  0.02820253 0.03933173 0.04271343\n",
      "  0.9705256 ]]\n",
      "[[0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 1]]\n",
      "[[15  0]\n",
      " [ 0 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        15\n",
      "         1.0       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        25\n",
      "   macro avg       1.00      1.00      1.00        25\n",
      "weighted avg       1.00      1.00      1.00        25\n",
      "\n",
      "Cohen's Kappa: 1.0\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "testResults = model.predict(testSamples)\n",
    "print(testResults.T)\n",
    "testResults = (testResults*2).astype(dtype=int) #conversion to (0,1)\n",
    "print(testResults.T)\n",
    "print(confusion_matrix(testLabels, testResults))\n",
    "print(classification_report(testLabels, testResults))\n",
    "print(\"Cohen's Kappa: {}\".format(cohen_kappa_score(testLabels, testResults)))\n",
    "print(\"Accuracy: \",accuracy_score(testLabels, testResults))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset with three classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 150\n",
      "Classes: {'Iris-versicolor', 'Iris-setosa', 'Iris-virginica'}\n",
      "Samples: (150, 4)\n",
      "Labels: (150,)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('iris.data')\n",
    "print(\"Rows:\",len(data))\n",
    "print(\"Classes:\",set(data['iris']))\n",
    "samples = data.to_numpy()[:,:4] \n",
    "labels = data.to_numpy()[:,4]\n",
    "samples = samples.astype(float)\n",
    "\n",
    "labels[labels[:]=='Iris-versicolor']=0\n",
    "labels[labels[:]=='Iris-setosa']=1\n",
    "labels[labels[:]=='Iris-virginica']=2\n",
    "labels = labels.astype(float)\n",
    "\n",
    "print(\"Samples:\",samples.shape)\n",
    "print(\"Labels:\",labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "(trainSamples, testSamples, trainLabels, testLabels) = sklearn.model_selection.train_test_split(samples, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss='binary_crossentropy', optimizer=\"adam\",metrics=['accuracy'])\n",
    "#model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\",metrics=['accuracy'])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.1814e-07 - accuracy: 0.3393\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 916us/step - loss: 1.1814e-07 - accuracy: 0.3393\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 960us/step - loss: 1.1814e-07 - accuracy: 0.3393\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.1814e-07 - accuracy: 0.3393\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 999us/step - loss: 1.1814e-07 - accuracy: 0.3393\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.1814e-07 - accuracy: 0.3393\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.1814e-07 - accuracy: 0.3393\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.1814e-07 - accuracy: 0.3393\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 917us/step - loss: 1.1814e-07 - accuracy: 0.3393\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 1.1814e-07 - accuracy: 0.3393\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(trainSamples, trainLabels, epochs=10,batch_size=10)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3 -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 -3\n",
      "  -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 -3]]\n",
      "[[ 0  0  0  0]\n",
      " [12  0  0  0]\n",
      " [13  0  0  0]\n",
      " [13  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -3.0       0.00      0.00      0.00       0.0\n",
      "         0.0       0.00      0.00      0.00      12.0\n",
      "         1.0       0.00      0.00      0.00      13.0\n",
      "         2.0       0.00      0.00      0.00      13.0\n",
      "\n",
      "    accuracy                           0.00      38.0\n",
      "   macro avg       0.00      0.00      0.00      38.0\n",
      "weighted avg       0.00      0.00      0.00      38.0\n",
      "\n",
      "Cohen's Kappa: 0.0\n",
      "Accuracy:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\programs\\miniconda3\\envs\\deep\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "testResults = model.predict(testSamples)\n",
    "testResults = (testResults*2).astype(dtype=int) #conversion to (0,1)\n",
    "print(testResults.T)\n",
    "print(confusion_matrix(testLabels, testResults))\n",
    "print(classification_report(testLabels, testResults))\n",
    "print(\"Cohen's Kappa: {}\".format(cohen_kappa_score(testLabels, testResults)))\n",
    "print(\"Accuracy: \",accuracy_score(testLabels, testResults))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the problem?\n",
    "The output is a number - no way that ANN learns the proper output!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)\n",
    "labels = tf.keras.utils.to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New model (output: vector of 3 values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 2,953\n",
      "Trainable params: 2,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=4, activation='sigmoid'))\n",
    "model.add(Dense(50, activation='sigmoid'))\n",
    "#model.add(Dense(1, activation='sigmoid'))\n",
    "#model.add(Dense(3, activation='sigmoid')) # three values\n",
    "model.add(Dense(3, activation='softmax')) # three values and normalization (output sums to 1)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainSamples, testSamples, trainLabels, testLabels) = sklearn.model_selection.train_test_split(samples, labels, random_state=1)\n",
    "#model.compile(loss='binary_crossentropy', optimizer=\"adam\",metrics=['accuracy'])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2916 - accuracy: 0.9732 - val_loss: 0.2983 - val_accuracy: 0.9737\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2834 - accuracy: 0.9643 - val_loss: 0.3068 - val_accuracy: 0.9737\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2828 - accuracy: 0.9464 - val_loss: 0.3056 - val_accuracy: 0.9737\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.9643 - val_loss: 0.2586 - val_accuracy: 0.9737\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 0.9732 - val_loss: 0.2685 - val_accuracy: 0.9737\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2557 - accuracy: 0.9732 - val_loss: 0.2441 - val_accuracy: 0.9737\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.9732 - val_loss: 0.2564 - val_accuracy: 0.9737\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2468 - accuracy: 0.9643 - val_loss: 0.2512 - val_accuracy: 0.9737\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2384 - accuracy: 0.9643 - val_loss: 0.2303 - val_accuracy: 0.9737\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2316 - accuracy: 0.9732 - val_loss: 0.2243 - val_accuracy: 0.9737\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(trainSamples, trainLabels, epochs=10,batch_size=10, validation_data=(testSamples,testLabels))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model (it is one-hot encoded!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.38383319e-02 9.76059556e-01 1.02132624e-04]\n",
      " [7.39345551e-01 2.26482570e-01 3.41719314e-02]\n",
      " [7.51825511e-01 4.69974726e-02 2.01177016e-01]\n",
      " [3.03408429e-02 9.69520092e-01 1.38990741e-04]\n",
      " [2.03958839e-01 2.70253909e-03 7.93338537e-01]\n",
      " [6.36820376e-01 2.60191709e-02 3.37160438e-01]\n",
      " [2.55525082e-01 3.91506776e-03 7.40559757e-01]\n",
      " [5.09643704e-02 9.48765635e-01 2.70026154e-04]\n",
      " [5.05072474e-02 9.49238241e-01 2.54531275e-04]\n",
      " [1.63960531e-01 1.90465676e-03 8.34134817e-01]\n",
      " [7.32738137e-01 4.05409262e-02 2.26720944e-01]\n",
      " [3.94790098e-02 9.60326791e-01 1.94269218e-04]\n",
      " [1.61174431e-01 1.81117898e-03 8.37014437e-01]\n",
      " [7.18133450e-01 3.93196866e-02 2.42546886e-01]\n",
      " [6.39053941e-01 2.51813252e-02 3.35764706e-01]\n",
      " [4.14355360e-02 9.58366871e-01 1.97606612e-04]\n",
      " [7.89292753e-01 6.20503761e-02 1.48656845e-01]\n",
      " [6.30324543e-01 2.46822089e-02 3.44993204e-01]\n",
      " [4.47748341e-02 9.55002606e-01 2.22549716e-04]\n",
      " [3.58956568e-02 9.63940144e-01 1.64195342e-04]\n",
      " [6.92520857e-01 3.13148573e-02 2.76164293e-01]\n",
      " [6.16151333e-01 2.31941622e-02 3.60654503e-01]\n",
      " [4.60471332e-01 1.12272399e-02 5.28301418e-01]\n",
      " [3.55816558e-02 9.64252353e-01 1.65963691e-04]\n",
      " [2.25033656e-01 3.06925550e-03 7.71897078e-01]\n",
      " [7.69500017e-01 5.38753904e-02 1.76624581e-01]\n",
      " [2.50451397e-02 9.74845409e-01 1.09494897e-04]\n",
      " [3.47292945e-02 9.65107501e-01 1.63253673e-04]\n",
      " [6.81031287e-01 2.95656007e-02 2.89403141e-01]\n",
      " [2.75642157e-01 4.21992689e-03 7.20138013e-01]\n",
      " [6.72587812e-01 2.96552554e-02 2.97756970e-01]\n",
      " [1.29441187e-01 1.29344931e-03 8.69265378e-01]\n",
      " [8.02600265e-01 7.23204240e-02 1.25079319e-01]\n",
      " [1.63252607e-01 1.84550171e-03 8.34901869e-01]\n",
      " [1.62580937e-01 1.87692500e-03 8.35542083e-01]\n",
      " [3.31972353e-02 9.66650426e-01 1.52284134e-04]\n",
      " [7.17109025e-01 3.51306386e-02 2.47760311e-01]\n",
      " [3.63587365e-02 9.63472903e-01 1.68375278e-04]]\n",
      "[1 0 0 1 2 0 2 1 1 2 0 1 2 0 0 1 0 0 1 1 0 0 2 1 2 0 1 1 0 2 0 2 0 2 2 1 0\n",
      " 1]\n",
      "[[15  0  1]\n",
      " [ 0 13  0]\n",
      " [ 0  0  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        16\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.97      0.98      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n",
      "Cohen's Kappa: 0.9597883597883597\n",
      "Accuracy:  0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "testResults = model.predict(testSamples)\n",
    "print(testResults)\n",
    "print(testResults.argmax(axis=1))\n",
    "\n",
    "print(confusion_matrix(testLabels.argmax(axis=1), testResults.argmax(axis=1)))\n",
    "print(classification_report(testLabels.argmax(axis=1), testResults.argmax(axis=1)))\n",
    "print(\"Cohen's Kappa: {}\".format(cohen_kappa_score(testLabels.argmax(axis=1), testResults.argmax(axis=1))))\n",
    "print(\"Accuracy: \",accuracy_score(testLabels.argmax(axis=1), testResults.argmax(axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4]] -> [[8.3436325e-02 7.0578331e-04 9.1585791e-01]]\n",
      "[0.73273814 0.04054093 0.22672094] -> [1. 0. 0.]\n",
      "[3.9479010e-02 9.6032679e-01 1.9426922e-04] -> [0. 1. 0.]\n",
      "[0.16117443 0.00181118 0.83701444] -> [0. 0. 1.]\n",
      "[0.71813345 0.03931969 0.24254689] -> [1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "sample = [[1,2,3,4]]\n",
    "pred = model.predict(sample)\n",
    "print(sample,'->',pred)\n",
    "\n",
    "pred = model.predict(testSamples[10:14])\n",
    "for p,t in zip(pred[0:4],testLabels[10:14]):\n",
    "    print(p,\"->\",t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('iris.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
