{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 2,851\n",
      "Trainable params: 2,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=4, activation='sigmoid'))\n",
    "model.add(Dense(50, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data (and remove one class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 150\n",
      "Rows after removal of 'Iris-virginica': 100\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('iris.data')\n",
    "print(\"Rows:\",len(data))\n",
    "data = data.drop(data[data.iris=='Iris-virginica'].index)\n",
    "print(\"Rows after removal of 'Iris-virginica':\",len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare samples and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: {'Iris-versicolor', 'Iris-setosa'}\n",
      "Classes after renaming: {0.0, 1.0}\n",
      "Samples: (100, 4)\n",
      "Labels: (100,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes:\",set(data['iris']))\n",
    "samples = data.to_numpy()[:,:4]\n",
    "samples = samples.astype(float)\n",
    "labels = data.to_numpy()[:,4]\n",
    "\n",
    "labels[labels[:]=='Iris-versicolor']=0\n",
    "labels[labels[:]=='Iris-setosa']=1\n",
    "#labels[labels[:]=='Iris-virginica']=2\n",
    "labels = labels.astype(float)\n",
    "print(\"Classes after renaming:\",set(labels))\n",
    "\n",
    "print(\"Samples:\",samples.shape)\n",
    "print(\"Labels:\",labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "(trainSamples, testSamples, trainLabels, testLabels) = sklearn.model_selection.train_test_split(samples, labels, random_state=1)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.8345 - accuracy: 0.4667\n",
      "Epoch 2/40\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.7202 - accuracy: 0.4667\n",
      "Epoch 3/40\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.4400\n",
      "Epoch 4/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6755 - accuracy: 0.5333\n",
      "Epoch 5/40\n",
      "8/8 [==============================] - 0s 871us/step - loss: 0.6647 - accuracy: 0.5467\n",
      "Epoch 6/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.9867\n",
      "Epoch 7/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6401 - accuracy: 1.0000\n",
      "Epoch 8/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6277 - accuracy: 1.0000\n",
      "Epoch 9/40\n",
      "8/8 [==============================] - 0s 875us/step - loss: 0.6144 - accuracy: 1.0000\n",
      "Epoch 10/40\n",
      "8/8 [==============================] - 0s 875us/step - loss: 0.6005 - accuracy: 1.0000\n",
      "Epoch 11/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5875 - accuracy: 1.0000\n",
      "Epoch 12/40\n",
      "8/8 [==============================] - 0s 750us/step - loss: 0.5675 - accuracy: 1.0000\n",
      "Epoch 13/40\n",
      "8/8 [==============================] - 0s 748us/step - loss: 0.5487 - accuracy: 1.0000\n",
      "Epoch 14/40\n",
      "8/8 [==============================] - 0s 1000us/step - loss: 0.5312 - accuracy: 1.0000\n",
      "Epoch 15/40\n",
      "8/8 [==============================] - 0s 880us/step - loss: 0.5102 - accuracy: 1.0000\n",
      "Epoch 16/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 1.0000\n",
      "Epoch 17/40\n",
      "8/8 [==============================] - 0s 875us/step - loss: 0.4666 - accuracy: 1.0000\n",
      "Epoch 18/40\n",
      "8/8 [==============================] - 0s 875us/step - loss: 0.4425 - accuracy: 1.0000\n",
      "Epoch 19/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4183 - accuracy: 1.0000\n",
      "Epoch 20/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3931 - accuracy: 1.0000\n",
      "Epoch 21/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3681 - accuracy: 1.0000\n",
      "Epoch 22/40\n",
      "8/8 [==============================] - 0s 875us/step - loss: 0.3446 - accuracy: 1.0000\n",
      "Epoch 23/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3164 - accuracy: 1.0000\n",
      "Epoch 24/40\n",
      "8/8 [==============================] - 0s 875us/step - loss: 0.2931 - accuracy: 1.0000\n",
      "Epoch 25/40\n",
      "8/8 [==============================] - 0s 750us/step - loss: 0.2700 - accuracy: 1.0000\n",
      "Epoch 26/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2480 - accuracy: 1.0000\n",
      "Epoch 27/40\n",
      "8/8 [==============================] - 0s 877us/step - loss: 0.2276 - accuracy: 1.0000\n",
      "Epoch 28/40\n",
      "8/8 [==============================] - 0s 874us/step - loss: 0.2077 - accuracy: 1.0000\n",
      "Epoch 29/40\n",
      "8/8 [==============================] - 0s 876us/step - loss: 0.1900 - accuracy: 1.0000\n",
      "Epoch 30/40\n",
      "8/8 [==============================] - 0s 874us/step - loss: 0.1744 - accuracy: 1.0000\n",
      "Epoch 31/40\n",
      "8/8 [==============================] - 0s 999us/step - loss: 0.1592 - accuracy: 1.0000\n",
      "Epoch 32/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1465 - accuracy: 1.0000\n",
      "Epoch 33/40\n",
      "8/8 [==============================] - 0s 875us/step - loss: 0.1334 - accuracy: 1.0000\n",
      "Epoch 34/40\n",
      "8/8 [==============================] - 0s 874us/step - loss: 0.1223 - accuracy: 1.0000\n",
      "Epoch 35/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1127 - accuracy: 1.0000\n",
      "Epoch 36/40\n",
      "8/8 [==============================] - 0s 875us/step - loss: 0.1039 - accuracy: 1.0000\n",
      "Epoch 37/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 1.0000\n",
      "Epoch 38/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0890 - accuracy: 1.0000\n",
      "Epoch 39/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0822 - accuracy: 1.0000\n",
      "Epoch 40/40\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0772 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(trainSamples, trainLabels, epochs=40,batch_size=10)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08033431 0.04314747 0.95484364 0.09771428 0.13670972 0.93077147\n",
      "  0.94171804 0.07977754 0.07769758 0.05428568 0.06858394 0.92679757\n",
      "  0.04012391 0.03452319 0.0482105  0.9527812  0.9116585  0.897305\n",
      "  0.04132044 0.9378116  0.93171155 0.04282522 0.05728498 0.06618777\n",
      "  0.93571883]]\n",
      "[[0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 1]]\n",
      "[[15  0]\n",
      " [ 0 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        15\n",
      "         1.0       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        25\n",
      "   macro avg       1.00      1.00      1.00        25\n",
      "weighted avg       1.00      1.00      1.00        25\n",
      "\n",
      "Cohen's Kappa: 1.0\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "testResults = model.predict(testSamples)\n",
    "print(testResults.T)\n",
    "testResults = np.where(np.array(testResults) >= 0.5,1, 0) #conversion to (0,1)\n",
    "print(testResults.T)\n",
    "print(confusion_matrix(testLabels, testResults))\n",
    "print(classification_report(testLabels, testResults))\n",
    "print(\"Cohen's Kappa: {}\".format(cohen_kappa_score(testLabels, testResults)))\n",
    "print(\"Accuracy: \",accuracy_score(testLabels, testResults))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset with three classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 150\n",
      "Classes: {'Iris-versicolor', 'Iris-setosa', 'Iris-virginica'}\n",
      "Samples: (150, 4)\n",
      "Labels: (150,)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('iris.data')\n",
    "print(\"Rows:\",len(data))\n",
    "print(\"Classes:\",set(data['iris']))\n",
    "samples = data.to_numpy()[:,:4] \n",
    "labels = data.to_numpy()[:,4]\n",
    "samples = samples.astype(float)\n",
    "\n",
    "labels[labels[:]=='Iris-versicolor']=0\n",
    "labels[labels[:]=='Iris-setosa']=1\n",
    "labels[labels[:]=='Iris-virginica']=2\n",
    "labels = labels.astype(float)\n",
    "\n",
    "print(\"Samples:\",samples.shape)\n",
    "print(\"Labels:\",labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "(trainSamples, testSamples, trainLabels, testLabels) = sklearn.model_selection.train_test_split(samples, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss='binary_crossentropy', optimizer=\"adam\",metrics=['accuracy'])\n",
    "#model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\",metrics=['accuracy'])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2027e-07 - accuracy: 0.3482\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2027e-07 - accuracy: 0.3482\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2027e-07 - accuracy: 0.3482\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2027e-07 - accuracy: 0.3482\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2027e-07 - accuracy: 0.3482\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2027e-07 - accuracy: 0.3482\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2027e-07 - accuracy: 0.3482\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.2027e-07 - accuracy: 0.3482\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 916us/step - loss: 1.2027e-07 - accuracy: 0.3482\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 1.2027e-07 - accuracy: 0.3482\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(trainSamples, trainLabels, epochs=10,batch_size=10)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0]]\n",
      "[[11  0  0]\n",
      " [17  0  0]\n",
      " [10  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.29      1.00      0.45        11\n",
      "         1.0       0.00      0.00      0.00        17\n",
      "         2.0       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.29        38\n",
      "   macro avg       0.10      0.33      0.15        38\n",
      "weighted avg       0.08      0.29      0.13        38\n",
      "\n",
      "Cohen's Kappa: 0.0\n",
      "Accuracy:  0.2894736842105263\n"
     ]
    }
   ],
   "source": [
    "testResults = model.predict(testSamples)\n",
    "testResults = (testResults*2).astype(dtype=int) #conversion to (0,1)\n",
    "print(testResults.T)\n",
    "print(confusion_matrix(testLabels, testResults))\n",
    "print(classification_report(testLabels, testResults))\n",
    "print(\"Cohen's Kappa: {}\".format(cohen_kappa_score(testLabels, testResults)))\n",
    "print(\"Accuracy: \",accuracy_score(testLabels, testResults))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the problem?\n",
    "The output is a number - no way that ANN learns the proper output!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)\n",
    "labels = tf.keras.utils.to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New model (output: vector of 3 values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 2,953\n",
      "Trainable params: 2,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=4, activation='sigmoid'))\n",
    "model.add(Dense(50, activation='sigmoid'))\n",
    "#model.add(Dense(1, activation='sigmoid'))\n",
    "#model.add(Dense(3, activation='sigmoid')) # three values\n",
    "model.add(Dense(3, activation='softmax')) # three values and normalization (output sums to 1)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainSamples, testSamples, trainLabels, testLabels) = sklearn.model_selection.train_test_split(samples, labels, random_state=1)\n",
    "#model.compile(loss='binary_crossentropy', optimizer=\"adam\",metrics=['accuracy'])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.8750 - val_loss: 0.4391 - val_accuracy: 0.8684\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.9375 - val_loss: 0.4140 - val_accuracy: 0.9737\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.9643 - val_loss: 0.4048 - val_accuracy: 0.9737\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.9643 - val_loss: 0.3954 - val_accuracy: 0.9737\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.9375 - val_loss: 0.3949 - val_accuracy: 0.9737\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.9643 - val_loss: 0.3716 - val_accuracy: 0.9737\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3649 - accuracy: 0.9643 - val_loss: 0.3585 - val_accuracy: 0.9737\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3536 - accuracy: 0.9464 - val_loss: 0.3658 - val_accuracy: 0.9737\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3418 - accuracy: 0.9643 - val_loss: 0.3355 - val_accuracy: 0.9737\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3371 - accuracy: 0.9643 - val_loss: 0.3360 - val_accuracy: 0.9737\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(trainSamples, trainLabels, epochs=10,batch_size=10, validation_data=(testSamples,testLabels))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model (it is one-hot encoded!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.1715456e-02 9.6760398e-01 6.8052724e-04]\n",
      " [6.4117455e-01 2.3931405e-01 1.1951135e-01]\n",
      " [6.1207223e-01 6.1629355e-02 3.2629842e-01]\n",
      " [4.0520120e-02 9.5851302e-01 9.6682331e-04]\n",
      " [3.0384314e-01 8.6544352e-03 6.8750238e-01]\n",
      " [5.4404843e-01 3.9496783e-02 4.1645470e-01]\n",
      " [3.3872056e-01 1.1110156e-02 6.5016931e-01]\n",
      " [6.8333514e-02 9.2965460e-01 2.0119210e-03]\n",
      " [6.7647591e-02 9.3041712e-01 1.9353941e-03]\n",
      " [2.7380857e-01 7.0889760e-03 7.1910250e-01]\n",
      " [5.9663814e-01 5.5134047e-02 3.4822789e-01]\n",
      " [5.3295724e-02 9.4529241e-01 1.4119048e-03]\n",
      " [2.6925173e-01 6.7243609e-03 7.2402394e-01]\n",
      " [5.9112102e-01 5.4033268e-02 3.5484573e-01]\n",
      " [5.4224795e-01 3.8177039e-02 4.1957507e-01]\n",
      " [5.4773796e-02 9.4377053e-01 1.4557235e-03]\n",
      " [6.3890636e-01 7.7652201e-02 2.8344148e-01]\n",
      " [5.3844148e-01 3.8022544e-02 4.2353600e-01]\n",
      " [6.0790382e-02 9.3754697e-01 1.6626309e-03]\n",
      " [4.8197769e-02 9.5060539e-01 1.1967651e-03]\n",
      " [5.6899858e-01 4.4373017e-02 3.8662842e-01]\n",
      " [5.3079909e-01 3.6435295e-02 4.3276557e-01]\n",
      " [4.4866529e-01 2.1268791e-02 5.3006601e-01]\n",
      " [4.7527950e-02 9.5127797e-01 1.1941589e-03]\n",
      " [3.1539273e-01 9.2130899e-03 6.7539412e-01]\n",
      " [6.2408108e-01 6.9732942e-02 3.0618599e-01]\n",
      " [3.3132717e-02 9.6613443e-01 7.3281396e-04]\n",
      " [4.6395943e-02 9.5243931e-01 1.1648553e-03]\n",
      " [5.6265628e-01 4.1990656e-02 3.9535302e-01]\n",
      " [3.4531432e-01 1.1222096e-02 6.4346355e-01]\n",
      " [5.6102037e-01 4.2942937e-02 3.9603665e-01]\n",
      " [2.4184078e-01 5.4508103e-03 7.5270844e-01]\n",
      " [6.5116656e-01 8.8107273e-02 2.6072615e-01]\n",
      " [2.7074486e-01 6.8385713e-03 7.2241664e-01]\n",
      " [2.7265427e-01 7.1217590e-03 7.2022390e-01]\n",
      " [4.4699971e-02 9.5421022e-01 1.0898206e-03]\n",
      " [5.8359683e-01 4.8884507e-02 3.6751863e-01]\n",
      " [4.9114112e-02 9.4965583e-01 1.2301448e-03]]\n",
      "[1 0 0 1 2 0 2 1 1 2 0 1 2 0 0 1 0 0 1 1 0 0 2 1 2 0 1 1 0 2 0 2 0 2 2 1 0\n",
      " 1]\n",
      "[[15  0  1]\n",
      " [ 0 13  0]\n",
      " [ 0  0  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        16\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.97      0.98      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n",
      "Cohen's Kappa: 0.9597883597883597\n",
      "Accuracy:  0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "testResults = model.predict(testSamples)\n",
    "print(testResults)\n",
    "print(testResults.argmax(axis=1))\n",
    "\n",
    "print(confusion_matrix(testLabels.argmax(axis=1), testResults.argmax(axis=1)))\n",
    "print(classification_report(testLabels.argmax(axis=1), testResults.argmax(axis=1)))\n",
    "print(\"Cohen's Kappa: {}\".format(cohen_kappa_score(testLabels.argmax(axis=1), testResults.argmax(axis=1))))\n",
    "print(\"Accuracy: \",accuracy_score(testLabels.argmax(axis=1), testResults.argmax(axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4]] -> [[0.19801329 0.00444155 0.7975451 ]]\n",
      "[0.59663814 0.05513405 0.3482279 ] -> [1. 0. 0.]\n",
      "[0.05329572 0.9452924  0.0014119 ] -> [0. 1. 0.]\n",
      "[0.26925173 0.00672436 0.72402394] -> [0. 0. 1.]\n",
      "[0.591121   0.05403327 0.35484573] -> [1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "sample = [[1,2,3,4]]\n",
    "pred = model.predict(sample)\n",
    "print(sample,'->',pred)\n",
    "\n",
    "pred = model.predict(testSamples[10:14])\n",
    "for p,t in zip(pred[0:4],testLabels[10:14]):\n",
    "    print(p,\"->\",t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('iris.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
